{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2706c8a8-783d-4200-945d-b8ab9fb83043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting to fetch Standard-legal cards...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Standard-legal cards...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fetched 175/3529 cards...\n",
      "INFO:__main__:Fetched 350/3529 cards...\n",
      "INFO:__main__:Fetched 525/3529 cards...\n",
      "INFO:__main__:Fetched 700/3529 cards...\n",
      "INFO:__main__:Fetched 875/3529 cards...\n",
      "INFO:__main__:Fetched 1050/3529 cards...\n",
      "INFO:__main__:Fetched 1225/3529 cards...\n",
      "INFO:__main__:Fetched 1400/3529 cards...\n",
      "INFO:__main__:Fetched 1575/3529 cards...\n",
      "INFO:__main__:Fetched 1750/3529 cards...\n",
      "INFO:__main__:Fetched 1925/3529 cards...\n",
      "INFO:__main__:Fetched 2100/3529 cards...\n",
      "INFO:__main__:Fetched 2275/3529 cards...\n",
      "INFO:__main__:Fetched 2450/3529 cards...\n",
      "INFO:__main__:Fetched 2625/3529 cards...\n",
      "INFO:__main__:Fetched 2800/3529 cards...\n",
      "INFO:__main__:Fetched 2975/3529 cards...\n",
      "INFO:__main__:Fetched 3150/3529 cards...\n",
      "INFO:__main__:Fetched 3325/3529 cards...\n",
      "INFO:__main__:Fetched 3500/3529 cards...\n",
      "INFO:__main__:Completed fetching 3529 cards\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing card data...\n",
      "Data saved to data\\standard_cards.csv\n",
      "\n",
      "Dataset Overview:\n",
      "Total cards: 3529\n",
      "\n",
      "Card type distribution:\n",
      "Creatures: 2009\n",
      "Lands: 204\n",
      "Instants/Sorceries: 777\n",
      "Legendary cards: 465\n",
      "\n",
      "Color distribution:\n",
      "Multicolored cards: 481\n",
      "0 color(s): 444 cards\n",
      "1 color(s): 2604 cards\n",
      "2 color(s): 431 cards\n",
      "3 color(s): 41 cards\n",
      "4 color(s): 1 cards\n",
      "5 color(s): 8 cards\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any, Optional\n",
    "import time\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "\n",
    "class ScryfallFetcher:\n",
    "    \"\"\"\n",
    "    A class to handle fetching and processing Magic: The Gathering cards from Scryfall API\n",
    "    with proper rate limiting and header handling\n",
    "    \"\"\"\n",
    "    \n",
    "    BASE_URL = \"https://api.scryfall.com\"\n",
    "    \n",
    "    def __init__(self, app_name: str = \"MTGDeckBuilder/1.0\"):\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': app_name,\n",
    "            'Accept': 'application/json'\n",
    "        })\n",
    "        \n",
    "        # Set up logging\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def _make_request(self, endpoint: str, params: Optional[Dict] = None, \n",
    "                     format_type: str = 'json') -> Dict:\n",
    "        \"\"\"\n",
    "        Make a request to Scryfall API with proper rate limiting and error handling\n",
    "        \n",
    "        Args:\n",
    "            endpoint: API endpoint to call\n",
    "            params: Query parameters\n",
    "            format_type: Response format (json, csv, text, image)\n",
    "        \"\"\"\n",
    "        if params is None:\n",
    "            params = {}\n",
    "            \n",
    "        if format_type != 'json':\n",
    "            params['format'] = format_type\n",
    "            \n",
    "        # Rate limiting - 100ms between requests as per documentation\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "        try:\n",
    "            response = self.session.get(f\"{self.BASE_URL}/{endpoint}\", params=params)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Handle different response formats\n",
    "            if format_type == 'json':\n",
    "                return response.json()\n",
    "            elif format_type == 'csv':\n",
    "                return response.text\n",
    "            else:\n",
    "                return response.content\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if response.status_code == 429:\n",
    "                self.logger.error(\"Rate limit exceeded. Waiting before retry...\")\n",
    "                time.sleep(1)  # Wait longer before retry\n",
    "                return self._make_request(endpoint, params, format_type)\n",
    "            else:\n",
    "                self.logger.error(f\"API request failed: {str(e)}\")\n",
    "                raise\n",
    "    \n",
    "    def get_standard_cards(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Fetch all Standard-legal cards with proper pagination handling\n",
    "        \"\"\"\n",
    "        cards = []\n",
    "        params = {\n",
    "            'q': 'format:standard legal:standard',\n",
    "            'unique': 'cards'\n",
    "        }\n",
    "        \n",
    "        self.logger.info(\"Starting to fetch Standard-legal cards...\")\n",
    "        \n",
    "        try:\n",
    "            # Initial request\n",
    "            response = self._make_request('cards/search', params)\n",
    "            cards.extend(response.get('data', []))\n",
    "            total_cards = response.get('total_cards', 0)\n",
    "            \n",
    "            # Handle pagination\n",
    "            while response.get('has_more'):\n",
    "                self.logger.info(f\"Fetched {len(cards)}/{total_cards} cards...\")\n",
    "                response = self._make_request(response['next_page'].replace(f\"{self.BASE_URL}/\", ''))\n",
    "                cards.extend(response.get('data', []))\n",
    "            \n",
    "            self.logger.info(f\"Completed fetching {len(cards)} cards\")\n",
    "            return cards\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error fetching cards: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def process_card_data(self, cards: List[Dict[str, Any]]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Process raw card data into a structured DataFrame with enhanced handling of special layouts\n",
    "        \"\"\"\n",
    "        processed_cards = []\n",
    "        \n",
    "        for card in cards:\n",
    "            # Handle split cards, adventures, and other special layouts\n",
    "            card_name = card.get('name')\n",
    "            if '//' in card_name:\n",
    "                # For split cards, store both the full name and the front face name\n",
    "                front_name = card_name.split('//')[0].strip()\n",
    "                \n",
    "                # Get face-specific data from card_faces\n",
    "                if 'card_faces' in card and card['card_faces']:\n",
    "                    front_face = card['card_faces'][0]\n",
    "                    mana_cost = front_face.get('mana_cost')\n",
    "                    colors = front_face.get('colors', card.get('colors', []))\n",
    "                    oracle_text = front_face.get('oracle_text')\n",
    "                    power = front_face.get('power')\n",
    "                    toughness = front_face.get('toughness')\n",
    "                else:\n",
    "                    mana_cost = card.get('mana_cost')\n",
    "                    colors = card.get('colors', [])\n",
    "                    oracle_text = card.get('oracle_text')\n",
    "                    power = card.get('power')\n",
    "                    toughness = card.get('toughness')\n",
    "                \n",
    "                # Store both names for reference\n",
    "                processed_card = {\n",
    "                    'name': front_name,  # Store front face name as primary name\n",
    "                    'full_name': card_name,  # Store full split name\n",
    "                    'layout': card.get('layout'),\n",
    "                    'mana_cost': mana_cost,\n",
    "                    'cmc': card.get('cmc'),\n",
    "                    'type_line': card.get('type_line'),\n",
    "                    'oracle_text': oracle_text,\n",
    "                    'colors': colors,\n",
    "                    'color_identity': card.get('color_identity', []),\n",
    "                    'power': power,\n",
    "                    'toughness': toughness,\n",
    "                    'rarity': card.get('rarity'),\n",
    "                    'set': card.get('set'),\n",
    "                    'collector_number': card.get('collector_number'),\n",
    "                    'keywords': card.get('keywords', []),\n",
    "                    'produced_mana': card.get('produced_mana', []),\n",
    "                    'legalities': card.get('legalities', {}),\n",
    "                }\n",
    "            else:\n",
    "                # Normal card processing\n",
    "                processed_card = {\n",
    "                    'name': card_name,\n",
    "                    'full_name': card_name,\n",
    "                    'layout': card.get('layout'),\n",
    "                    'mana_cost': card.get('mana_cost'),\n",
    "                    'cmc': card.get('cmc'),\n",
    "                    'type_line': card.get('type_line'),\n",
    "                    'oracle_text': card.get('oracle_text'),\n",
    "                    'colors': card.get('colors', []),\n",
    "                    'color_identity': card.get('color_identity', []),\n",
    "                    'power': card.get('power'),\n",
    "                    'toughness': card.get('toughness'),\n",
    "                    'rarity': card.get('rarity'),\n",
    "                    'set': card.get('set'),\n",
    "                    'collector_number': card.get('collector_number'),\n",
    "                    'keywords': card.get('keywords', []),\n",
    "                    'produced_mana': card.get('produced_mana', []),\n",
    "                    'legalities': card.get('legalities', {}),\n",
    "                }\n",
    "            \n",
    "            # Add derived features\n",
    "            processed_card.update({\n",
    "                'is_creature': 'Creature' in card.get('type_line', ''),\n",
    "                'is_land': 'Land' in card.get('type_line', ''),\n",
    "                'is_instant_sorcery': any(t in card.get('type_line', '') \n",
    "                                        for t in ['Instant', 'Sorcery']),\n",
    "                'is_multicolored': len(processed_card['colors']) > 1,\n",
    "                'color_count': len(processed_card['colors']),\n",
    "                'has_etb_effect': 'enters the battlefield' in (processed_card['oracle_text'] or '').lower(),\n",
    "                'is_legendary': 'Legendary' in card.get('type_line', '')\n",
    "            })\n",
    "            \n",
    "            processed_cards.append(processed_card)\n",
    "            \n",
    "        return pd.DataFrame(processed_cards)\n",
    "\n",
    "    def save_to_csv(self, df: pd.DataFrame, filename: str = None) -> str:\n",
    "        \"\"\"\n",
    "        Save the processed cards to a CSV file in the data directory\n",
    "        \"\"\"\n",
    "        # Create data directory if it doesn't exist\n",
    "        data_dir = 'data'\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "        \n",
    "        if filename is None:\n",
    "            filename = f\"standard_cards.csv\"\n",
    "        \n",
    "        # Construct full path\n",
    "        filepath = os.path.join(data_dir, filename)\n",
    "        \n",
    "        df.to_csv(filepath, index=False)\n",
    "        return filepath\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to demonstrate usage\n",
    "    \"\"\"\n",
    "    fetcher = ScryfallFetcher()\n",
    "    \n",
    "    try:\n",
    "        print(\"Fetching Standard-legal cards...\")\n",
    "        cards = fetcher.get_standard_cards()\n",
    "        \n",
    "        print(\"Processing card data...\")\n",
    "        df = fetcher.process_card_data(cards)\n",
    "        \n",
    "        filename = fetcher.save_to_csv(df)\n",
    "        print(f\"Data saved to {filename}\")\n",
    "        \n",
    "        print(\"\\nDataset Overview:\")\n",
    "        print(f\"Total cards: {len(df)}\")\n",
    "        print(\"\\nCard type distribution:\")\n",
    "        print(f\"Creatures: {df['is_creature'].sum()}\")\n",
    "        print(f\"Lands: {df['is_land'].sum()}\")\n",
    "        print(f\"Instants/Sorceries: {df['is_instant_sorcery'].sum()}\")\n",
    "        print(f\"Legendary cards: {df['is_legendary'].sum()}\")\n",
    "        \n",
    "        print(\"\\nColor distribution:\")\n",
    "        print(f\"Multicolored cards: {df['is_multicolored'].sum()}\")\n",
    "        color_counts = df['color_count'].value_counts().sort_index()\n",
    "        for count, num_cards in color_counts.items():\n",
    "            print(f\"{count} color(s): {num_cards} cards\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a51c836-4ae5-4c5c-bc04-419811f22fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Gruul Midrange Analysis ===\n",
      "\n",
      "Deck Validation:\n",
      "✓ Deck is valid\n",
      "\n",
      "Detected Archetype: tempo\n",
      "Archetype Fit Score: 64.53%\n",
      "\n",
      "Mana Curve:\n",
      "CMC 1: ██████████████ 14 cards\n",
      "CMC 2: ███████████████████ 19 cards\n",
      "CMC 3: ██████ 6 cards\n",
      "\n",
      "Card Categories:\n",
      "Creatures: 56.4%\n",
      "Removal: 23.1%\n",
      "Interaction: 56.4%\n",
      "Cantrips: 20.5%\n",
      "Threats: 20.5%\n",
      "\n",
      "Archetype-based Recommendations:\n",
      "- Adjust threat count to around 40% for tempo\n",
      "- Adjust interaction count to around 30% for tempo\n",
      "- Adjust creature count to around 40% for tempo\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from enum import Enum\n",
    "from collections import Counter\n",
    "import time\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "\n",
    "class DeckArchetype(Enum):\n",
    "    AGGRO = \"aggro\"\n",
    "    MIDRANGE = \"midrange\"\n",
    "    CONTROL = \"control\"\n",
    "    TEMPO = \"tempo\"\n",
    "    COMBO = \"combo\"\n",
    "    UNKNOWN = \"unknown\"\n",
    "\n",
    "class DeckValidator:\n",
    "    \"\"\"\n",
    "    A class to validate Magic: The Gathering decks and provide deck construction insights\n",
    "    \"\"\"\n",
    "    \n",
    "    STANDARD_DECK_SIZE = 60\n",
    "    MAX_COPIES = 4\n",
    "    RECOMMENDED_LAND_RATIO = (0.33, 0.42)  # Min and max recommended land percentages\n",
    "    \n",
    "    def __init__(self, card_database: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Initialize with a card database (from ScryfallFetcher)\n",
    "        \"\"\"\n",
    "        self.card_db = card_database\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def validate_deck(self, decklist: List[str]) -> Tuple[bool, List[str]]:\n",
    "        \"\"\"\n",
    "        Validate a deck against Standard format rules\n",
    "        Returns: (is_valid, list_of_issues)\n",
    "        \"\"\"\n",
    "        issues = []\n",
    "        \n",
    "        # Convert decklist to card counts\n",
    "        try:\n",
    "            deck_counts = Counter(decklist)\n",
    "        except Exception as e:\n",
    "            issues.append(f\"Error processing decklist: {str(e)}\")\n",
    "            return False, issues\n",
    "            \n",
    "        # Check deck size\n",
    "        if len(decklist) < self.STANDARD_DECK_SIZE:\n",
    "            issues.append(f\"Deck contains {len(decklist)} cards. Minimum is {self.STANDARD_DECK_SIZE}\")\n",
    "            \n",
    "        # Validate card counts and legality\n",
    "        for card_name, count in deck_counts.items():\n",
    "            # Check if card exists in database\n",
    "            card_data = self.card_db[self.card_db['name'] == card_name]\n",
    "            if len(card_data) == 0:\n",
    "                issues.append(f\"Card not found in database: {card_name}\")\n",
    "                continue\n",
    "                \n",
    "            # Check copy limit\n",
    "            if count > self.MAX_COPIES and 'Basic' not in card_data['type_line'].iloc[0]:\n",
    "                issues.append(f\"Too many copies of {card_name}: {count} (max {self.MAX_COPIES})\")\n",
    "        \n",
    "        return len(issues) == 0, issues\n",
    "\n",
    "class DeckCurveAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyzer for deck curve characteristics based on archetype patterns\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ideal curve characteristics by archetype\n",
    "    ARCHETYPE_PATTERNS = {\n",
    "        DeckArchetype.AGGRO: {\n",
    "            'peak_cmc': 2,\n",
    "            'max_curve_point': 3,\n",
    "            'early_game_weight': 0.7,  # 70% of spells should be 1-2 CMC\n",
    "            'removal_ratio': 0.15,     # 15% removal spells\n",
    "            'creature_ratio': 0.6      # 60% creatures\n",
    "        },\n",
    "        DeckArchetype.MIDRANGE: {\n",
    "            'peak_cmc': 3,\n",
    "            'max_curve_point': 5,\n",
    "            'curve_distribution': 'normal',\n",
    "            'removal_ratio': 0.25,\n",
    "            'creature_ratio': 0.5\n",
    "        },\n",
    "        DeckArchetype.CONTROL: {\n",
    "            'peak_cmc': 4,\n",
    "            'max_curve_point': 7,\n",
    "            'early_interaction_ratio': 0.3,  # 30% early interaction spells\n",
    "            'removal_ratio': 0.35,\n",
    "            'creature_ratio': 0.2\n",
    "        },\n",
    "        DeckArchetype.TEMPO: {\n",
    "            'peak_cmc': 2,\n",
    "            'max_curve_point': 4,\n",
    "            'threat_ratio': 0.4,       # 40% threat spells\n",
    "            'interaction_ratio': 0.3,   # 30% interaction spells\n",
    "            'creature_ratio': 0.4\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.interaction_keywords = [\n",
    "            'counter', 'return target', 'destroy target', 'exile target',\n",
    "            'can\\'t attack', 'can\\'t block', 'tap target', 'counter target'\n",
    "        ]\n",
    "        self.removal_keywords = [\n",
    "            'destroy', 'exile', 'damage to target', 'dies', '-X/-X'\n",
    "        ]\n",
    "        self.cantrip_keywords = [\n",
    "            'draw a card', 'look at the top', 'scry', 'surveil'\n",
    "        ]\n",
    "    \n",
    "    def analyze_curve(self, deck_cards: pd.DataFrame, decklist: List[str]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Analyze mana curve and detect likely archetype\n",
    "        \"\"\"\n",
    "        # Calculate basic curve\n",
    "        curve = self._calculate_detailed_curve(deck_cards, decklist)\n",
    "        \n",
    "        # Analyze card categories\n",
    "        categories = self._categorize_cards(deck_cards, decklist)\n",
    "        \n",
    "        # Detect archetype\n",
    "        archetype = self._detect_archetype(curve, categories)\n",
    "        \n",
    "        # Generate archetype-specific analysis\n",
    "        analysis = self._analyze_for_archetype(curve, categories, archetype)\n",
    "        \n",
    "        return {\n",
    "            'curve': curve,\n",
    "            'categories': categories,\n",
    "            'archetype': archetype,\n",
    "            'analysis': analysis\n",
    "        }\n",
    "    \n",
    "    def _calculate_detailed_curve(self, deck_cards: pd.DataFrame, decklist: List[str]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Calculate detailed mana curve statistics\n",
    "        \"\"\"\n",
    "        curve_counts = Counter()\n",
    "        spell_counts = Counter()\n",
    "        \n",
    "        for _, card in deck_cards.iterrows():\n",
    "            count = decklist.count(card['name'])\n",
    "            cmc = int(card['cmc'])\n",
    "            \n",
    "            if not card['is_land']:\n",
    "                curve_counts[cmc] += count\n",
    "                if self._is_spell(card):\n",
    "                    spell_counts[cmc] += count\n",
    "        \n",
    "        total_spells = sum(curve_counts.values())\n",
    "        if total_spells == 0:\n",
    "            return {\n",
    "                'curve': {},\n",
    "                'spell_curve': {},\n",
    "                'percentages': {},\n",
    "                'avg_cmc': 0,\n",
    "                'peak_cmc': 0\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            'curve': dict(sorted(curve_counts.items())),\n",
    "            'spell_curve': dict(sorted(spell_counts.items())),\n",
    "            'percentages': {\n",
    "                cmc: count/total_spells \n",
    "                for cmc, count in curve_counts.items()\n",
    "            },\n",
    "            'avg_cmc': sum(cmc * count for cmc, count in curve_counts.items()) / total_spells,\n",
    "            'peak_cmc': max(curve_counts.items(), key=lambda x: x[1])[0] if curve_counts else 0\n",
    "        }\n",
    "    \n",
    "    def _categorize_cards(self, deck_cards: pd.DataFrame, decklist: List[str]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Categorize cards by their role in the deck\n",
    "        \"\"\"\n",
    "        categories = {\n",
    "            'creatures': 0,\n",
    "            'removal': 0,\n",
    "            'interaction': 0,\n",
    "            'cantrips': 0,\n",
    "            'threats': 0\n",
    "        }\n",
    "        \n",
    "        total_nonland_cards = 0\n",
    "        \n",
    "        for _, card in deck_cards.iterrows():\n",
    "            if card['is_land']:\n",
    "                continue\n",
    "                \n",
    "            count = decklist.count(card['name'])\n",
    "            total_nonland_cards += count\n",
    "            \n",
    "            # Categorize card\n",
    "            if card['is_creature']:\n",
    "                categories['creatures'] += count\n",
    "                if self._is_threat(card):\n",
    "                    categories['threats'] += count\n",
    "                    \n",
    "            if self._has_removal(card):\n",
    "                categories['removal'] += count\n",
    "                \n",
    "            if self._is_interaction(card):\n",
    "                categories['interaction'] += count\n",
    "                \n",
    "            if self._is_cantrip(card):\n",
    "                categories['cantrips'] += count\n",
    "        \n",
    "        # Convert to ratios\n",
    "        if total_nonland_cards == 0:\n",
    "            return {category: 0.0 for category in categories}\n",
    "            \n",
    "        return {\n",
    "            category: count/total_nonland_cards \n",
    "            for category, count in categories.items()\n",
    "        }\n",
    "    \n",
    "    def _detect_archetype(self, curve: Dict, categories: Dict) -> DeckArchetype:\n",
    "        \"\"\"\n",
    "        Detect the most likely archetype based on curve and card categories\n",
    "        \"\"\"\n",
    "        scores = {archetype: 0 for archetype in DeckArchetype}\n",
    "        \n",
    "        # Analyze curve shape\n",
    "        if curve['peak_cmc'] <= 2 and categories['creatures'] >= 0.5:\n",
    "            scores[DeckArchetype.AGGRO] += 2\n",
    "            \n",
    "        if 2 <= curve['peak_cmc'] <= 3 and 0.4 <= categories['creatures'] <= 0.6:\n",
    "            scores[DeckArchetype.MIDRANGE] += 2\n",
    "            \n",
    "        if curve['peak_cmc'] >= 4 and categories['interaction'] >= 0.25:\n",
    "            scores[DeckArchetype.CONTROL] += 2\n",
    "            \n",
    "        if curve['peak_cmc'] <= 3 and categories['interaction'] >= 0.25:\n",
    "            scores[DeckArchetype.TEMPO] += 2\n",
    "        \n",
    "        # Analyze card ratios\n",
    "        if categories['removal'] >= 0.3:\n",
    "            scores[DeckArchetype.CONTROL] += 1\n",
    "            \n",
    "        if categories['cantrips'] >= 0.15:\n",
    "            scores[DeckArchetype.CONTROL] += 1\n",
    "            scores[DeckArchetype.TEMPO] += 1\n",
    "            \n",
    "        if categories['threats'] >= 0.4:\n",
    "            scores[DeckArchetype.AGGRO] += 1\n",
    "            \n",
    "        return max(scores.items(), key=lambda x: x[1])[0]\n",
    "    \n",
    "    def _analyze_for_archetype(self, curve: Dict, categories: Dict, \n",
    "                             archetype: DeckArchetype) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generate archetype-specific analysis and recommendations\n",
    "        \"\"\"\n",
    "        pattern = self.ARCHETYPE_PATTERNS.get(archetype)\n",
    "        if not pattern:\n",
    "            return {}\n",
    "            \n",
    "        recommendations = []\n",
    "        \n",
    "        # Check curve against archetype pattern\n",
    "        if curve['peak_cmc'] != pattern['peak_cmc']:\n",
    "            recommendations.append(\n",
    "                f\"Consider adjusting curve peak to {pattern['peak_cmc']} CMC \"\n",
    "                f\"for optimal {archetype.value} performance\"\n",
    "            )\n",
    "        \n",
    "        # Check ratios\n",
    "        for category, target_ratio in pattern.items():\n",
    "            if category.endswith('_ratio'):\n",
    "                actual_ratio = categories.get(category.replace('_ratio', ''), 0)\n",
    "                if abs(actual_ratio - target_ratio) > 0.1:\n",
    "                    recommendations.append(\n",
    "                        f\"Adjust {category.replace('_ratio', '')} count to around \"\n",
    "                        f\"{target_ratio:.0%} for {archetype.value}\"\n",
    "                    )\n",
    "        \n",
    "        return {\n",
    "            'archetype_fit': self._calculate_archetype_fit(curve, categories, pattern),\n",
    "            'recommendations': recommendations,\n",
    "            'ideal_pattern': pattern\n",
    "        }\n",
    "    \n",
    "    def _calculate_archetype_fit(self, curve: Dict, categories: Dict, \n",
    "                               pattern: Dict) -> float:\n",
    "        \"\"\"\n",
    "        Calculate how well the deck fits its detected archetype\n",
    "        \"\"\"\n",
    "        differences = []\n",
    "        \n",
    "        for category, target in pattern.items():\n",
    "            if category.endswith('_ratio'):\n",
    "                actual = categories.get(category.replace('_ratio', ''), 0)\n",
    "                differences.append(abs(actual - target))\n",
    "                \n",
    "        if differences:\n",
    "            return 1 - (sum(differences) / len(differences))\n",
    "        return 0.5\n",
    "    \n",
    "    def _is_spell(self, card: pd.Series) -> bool:\n",
    "        return not card['is_land']\n",
    "    \n",
    "    def _is_threat(self, card: pd.Series) -> bool:\n",
    "        return (card['is_creature'] and \n",
    "                (card['power'] is not None and float(card['power']) >= 3))\n",
    "    \n",
    "    def _has_removal(self, card: pd.Series) -> bool:\n",
    "        return any(keyword in (card['oracle_text'] or '').lower() \n",
    "                  for keyword in self.removal_keywords)\n",
    "    \n",
    "    def _is_interaction(self, card: pd.Series) -> bool:\n",
    "        return any(keyword in (card['oracle_text'] or '').lower() \n",
    "                  for keyword in self.interaction_keywords)\n",
    "    \n",
    "    def _is_cantrip(self, card: pd.Series) -> bool:\n",
    "        return any(keyword in (card['oracle_text'] or '').lower() \n",
    "                  for keyword in self.cantrip_keywords)\n",
    "\n",
    "# Example usage\n",
    "def analyze_gruul_midrange(cards_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Analyze Gruul Midrange deck\n",
    "    \"\"\"\n",
    "    # Gruul Midrange decklist\n",
    "    decklist = [\n",
    "        \"Afterburner Expert\"] * 4 + [\n",
    "        \"Commercial District\"] * 1 + [\n",
    "        \"Copperline Gorge\"] * 4 + [\n",
    "        \"Draconautics Engineer\"] * 4 + [\n",
    "        \"Dredger's Insight\"] * 4 + [\n",
    "        \"Fear of Missing Out\"] * 4 + [\n",
    "        \"Forest\"] * 4 + [\n",
    "        \"Inti, Seneschal of the Sun\"] * 2 + [\n",
    "        \"Karplusan Forest\"] * 4 + [\n",
    "        \"Mountain\"] * 1 + [\n",
    "        \"Obliterating Bolt\"] * 2 + [\n",
    "        \"Patchwork Beastie\"] * 4 + [\n",
    "        \"Pawpatch Recruit\"] * 2 + [\n",
    "        \"Questing Druid\"] * 2 + [\n",
    "        \"Restless Ridgeline\"] * 3 + [\n",
    "        \"Scorching Shot\"] * 1 + [\n",
    "        \"Seed of Hope\"] * 4 + [\n",
    "        \"Thornspire Verge\"] * 4 + [\n",
    "        \"Torch the Tower\"] * 4 + [\n",
    "        \"Wrenn and Realmbreaker\"] * 2\n",
    "    \n",
    "    # Initialize analyzers\n",
    "    validator = DeckValidator(cards_df)\n",
    "    curve_analyzer = DeckCurveAnalyzer()\n",
    "    \n",
    "    # Validate deck\n",
    "    is_valid, issues = validator.validate_deck(decklist)\n",
    "    print(\"=== Gruul Midrange Analysis ===\\n\")\n",
    "    print(\"Deck Validation:\")\n",
    "    if issues:\n",
    "        print(\"Issues found:\")\n",
    "        for issue in issues:\n",
    "            print(f\"- {issue}\")\n",
    "    else:\n",
    "        print(\"✓ Deck is valid\")\n",
    "    \n",
    "    # Analyze curve and archetype\n",
    "    deck_cards = cards_df[cards_df['name'].isin(decklist)]\n",
    "    analysis = curve_analyzer.analyze_curve(deck_cards, decklist)\n",
    "    \n",
    "    print(f\"\\nDetected Archetype: {analysis['archetype'].value}\")\n",
    "    print(f\"Archetype Fit Score: {analysis['analysis']['archetype_fit']:.2%}\")\n",
    "    \n",
    "    print(\"\\nMana Curve:\")\n",
    "    for cmc, count in analysis['curve']['curve'].items():\n",
    "        print(f\"CMC {cmc}: {'█' * count} {count} cards\")\n",
    "    \n",
    "    print(\"\\nCard Categories:\")\n",
    "    for category, ratio in analysis['categories'].items():\n",
    "        print(f\"{category.title()}: {ratio:.1%}\")\n",
    "    \n",
    "    if analysis['analysis']['recommendations']:\n",
    "        print(\"\\nArchetype-based Recommendations:\")\n",
    "        for rec in analysis['analysis']['recommendations']:\n",
    "            print(f\"- {rec}\")\n",
    "\n",
    "cards_df = pd.read_csv('data/standard_cards.csv')\n",
    "analyze_gruul_midrange(cards_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfbf1cf0-4ea4-437f-ac9c-82c7863e69bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15 decklists\n",
      "\n",
      "=== Standard Format Analysis ===\n",
      "\n",
      "Format Characteristics:\n",
      "Speed: fast\n",
      "Effective number of archetypes: 2.89\n",
      "\n",
      "Most Common Mechanics:\n",
      "- token: 613 cards\n",
      "- flying: 487 cards\n",
      "- Flying: 369 cards\n",
      "- trample: 213 cards\n",
      "- haste: 212 cards\n",
      "\n",
      "Archetype Distribution:\n",
      "aggro: 53.3% (8 decks)\n",
      "hybrid: 33.3% (5 decks)\n",
      "tempo: 6.7% (1 decks)\n",
      "midrange: 6.7% (1 decks)\n",
      "\n",
      "Most Played Cards (excluding lands):\n",
      "Floodpits Drowner: 12 copies\n",
      "Novice Inspector: 12 copies\n",
      "Sheltered by Ghosts: 12 copies\n",
      "Spyglass Siren: 12 copies\n",
      "\n",
      "Deck Analysis:\n",
      "\n",
      "Azorius Convoke:\n",
      "Archetype: aggro\n",
      "Format Alignment: 1.00\n",
      "\n",
      "Azorius Oculus:\n",
      "Archetype: hybrid\n",
      "Subtype: aggro-tempo\n",
      "Format Alignment: 1.00\n",
      "\n",
      "Boros Tokens:\n",
      "Archetype: aggro\n",
      "Format Alignment: 1.00\n",
      "\n",
      "Dimir Enchantments:\n",
      "Archetype: tempo\n",
      "Format Alignment: 1.00\n",
      "\n",
      "Dimir Midrange:\n",
      "Archetype: hybrid\n",
      "Subtype: aggro-tempo\n",
      "Format Alignment: 1.00\n",
      "\n",
      "Esper Pixie :\n",
      "Archetype: hybrid\n",
      "Subtype: aggro-midrange\n",
      "Format Alignment: 1.00\n",
      "\n",
      "Golgari Midrange:\n",
      "Archetype: hybrid\n",
      "Subtype: aggro-midrange\n",
      "Format Alignment: 1.00\n",
      "\n",
      "Gruul Aggro:\n",
      "Archetype: aggro\n",
      "Format Alignment: 1.00\n",
      "\n",
      "Gruul Delirium:\n",
      "Archetype: aggro\n",
      "Format Alignment: 1.00\n",
      "\n",
      "Gruul Midrange:\n",
      "Archetype: aggro\n",
      "Format Alignment: 1.00\n",
      "\n",
      "Jeskai Convoke:\n",
      "Archetype: aggro\n",
      "Format Alignment: 1.00\n",
      "\n",
      "Mono-Red Aggro:\n",
      "Archetype: aggro\n",
      "Format Alignment: 1.00\n",
      "\n",
      "Mono-White Caretaker:\n",
      "Archetype: hybrid\n",
      "Subtype: midrange-tempo\n",
      "Format Alignment: 1.00\n",
      "\n",
      "Selesnya Midrange:\n",
      "Archetype: aggro\n",
      "Format Alignment: 1.00\n",
      "\n",
      "Zur Overlords:\n",
      "Archetype: midrange\n",
      "Format Alignment: 1.00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Tuple, Set\n",
    "from collections import Counter, defaultdict\n",
    "from enum import Enum\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class ArchetypeCharacteristics:\n",
    "    \"\"\"Characteristics that define an archetype\"\"\"\n",
    "    creature_ratio: Tuple[float, float]  # min, max\n",
    "    removal_ratio: Tuple[float, float]\n",
    "    curve_peak: Tuple[int, int]  # min, max CMC\n",
    "    interaction_ratio: Tuple[float, float]\n",
    "    card_advantage_ratio: Tuple[float, float]\n",
    "    avg_cmc: Tuple[float, float]\n",
    "\n",
    "class DeckArchetype(Enum):\n",
    "    AGGRO = \"aggro\"\n",
    "    MIDRANGE = \"midrange\"\n",
    "    CONTROL = \"control\"\n",
    "    TEMPO = \"tempo\"\n",
    "    COMBO = \"combo\"\n",
    "    HYBRID = \"hybrid\"\n",
    "    UNKNOWN = \"unknown\"\n",
    "\n",
    "    @classmethod\n",
    "    def get_characteristics(cls) -> Dict['DeckArchetype', ArchetypeCharacteristics]:\n",
    "        return {\n",
    "            cls.AGGRO: ArchetypeCharacteristics(\n",
    "                creature_ratio=(0.45, 0.75),\n",
    "                removal_ratio=(0.1, 0.3),\n",
    "                curve_peak=(1, 2),\n",
    "                interaction_ratio=(0.0, 0.2),\n",
    "                card_advantage_ratio=(0.0, 0.15),\n",
    "                avg_cmc=(1.5, 2.5)\n",
    "            ),\n",
    "            cls.MIDRANGE: ArchetypeCharacteristics(\n",
    "                creature_ratio=(0.35, 0.55),\n",
    "                removal_ratio=(0.15, 0.35),\n",
    "                curve_peak=(2, 4),\n",
    "                interaction_ratio=(0.1, 0.3),\n",
    "                card_advantage_ratio=(0.1, 0.3),\n",
    "                avg_cmc=(2.5, 3.5)\n",
    "            ),\n",
    "            cls.CONTROL: ArchetypeCharacteristics(\n",
    "                creature_ratio=(0.1, 0.3),\n",
    "                removal_ratio=(0.25, 0.45),\n",
    "                curve_peak=(2, 5),\n",
    "                interaction_ratio=(0.25, 0.5),\n",
    "                card_advantage_ratio=(0.2, 0.4),\n",
    "                avg_cmc=(3.0, 4.5)\n",
    "            ),\n",
    "            cls.TEMPO: ArchetypeCharacteristics(\n",
    "                creature_ratio=(0.3, 0.5),\n",
    "                removal_ratio=(0.15, 0.35),\n",
    "                curve_peak=(1, 3),\n",
    "                interaction_ratio=(0.2, 0.4),\n",
    "                card_advantage_ratio=(0.1, 0.25),\n",
    "                avg_cmc=(2.0, 3.0)\n",
    "            )\n",
    "        }\n",
    "\n",
    "class CardCategory(Enum):\n",
    "    LAND = \"land\"\n",
    "    CREATURE = \"creature\"\n",
    "    REMOVAL = \"removal\"\n",
    "    CARD_ADVANTAGE = \"card_advantage\"\n",
    "    INTERACTION = \"interaction\"\n",
    "    UTILITY = \"utility\"\n",
    "    RAMP = \"ramp\"\n",
    "    FINISHER = \"finisher\"\n",
    "\n",
    "def safe_parse_list(list_str: str) -> List[str]:\n",
    "    \"\"\"Safely parse a string representation of a list\"\"\"\n",
    "    if not list_str or not isinstance(list_str, str):\n",
    "        return []\n",
    "    try:\n",
    "        if list_str.startswith('[') and list_str.endswith(']'):\n",
    "            # Remove brackets and split by comma\n",
    "            items = list_str[1:-1].split(',')\n",
    "            # Clean up each item\n",
    "            return [item.strip().strip('\"\\'') for item in items if item.strip()]\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Error parsing list string: {list_str}\")\n",
    "        return []\n",
    "\n",
    "def load_and_preprocess_data(csv_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load and preprocess card data with correct data types\"\"\"\n",
    "    # Define dtypes for columns\n",
    "    dtypes = {\n",
    "        'name': str,\n",
    "        'full_name': str,\n",
    "        'layout': str,\n",
    "        'mana_cost': str,\n",
    "        'cmc': float,\n",
    "        'type_line': str,\n",
    "        'oracle_text': str,\n",
    "        'colors': str,\n",
    "        'color_identity': str,\n",
    "        'power': str,\n",
    "        'toughness': str,\n",
    "        'rarity': str,\n",
    "        'set': str,\n",
    "        'collector_number': str,\n",
    "        'keywords': str,\n",
    "        'produced_mana': str,\n",
    "        'legalities': str,\n",
    "        'is_creature': bool,\n",
    "        'is_land': bool,\n",
    "        'is_instant_sorcery': bool,\n",
    "        'is_multicolored': bool,\n",
    "        'color_count': int,\n",
    "        'has_etb_effect': bool,\n",
    "        'is_legendary': bool\n",
    "    }\n",
    "\n",
    "    # Read CSV with specified dtypes\n",
    "    df = pd.read_csv(csv_path, dtype=dtypes)\n",
    "    \n",
    "    # Handle any missing values\n",
    "    string_columns = ['name', 'full_name', 'layout', 'mana_cost', 'type_line', \n",
    "                     'oracle_text', 'colors', 'color_identity', 'power', 'toughness',\n",
    "                     'keywords', 'produced_mana']\n",
    "    for col in string_columns:\n",
    "        df[col] = df[col].fillna('')\n",
    "    \n",
    "    # Create additional columns for split card handling\n",
    "    df['alternative_names'] = df['name'].apply(lambda x: [x.strip() for x in x.split('//') if x.strip()])\n",
    "    df['name_lower'] = df['name'].str.lower()\n",
    "    \n",
    "    # Convert list-like strings to actual lists using safe parser\n",
    "    list_columns = ['colors', 'color_identity', 'keywords', 'produced_mana']\n",
    "    for col in list_columns:\n",
    "        df[col] = df[col].apply(safe_parse_list)\n",
    "\n",
    "    return df\n",
    "\n",
    "class CardMechanics:\n",
    "    \"\"\"Analyzer for card mechanics and keywords\"\"\"\n",
    "    def __init__(self, card_db: pd.DataFrame):\n",
    "        self.card_db = card_db\n",
    "        self.format_mechanics = self._identify_format_mechanics()\n",
    "        \n",
    "    def _identify_format_mechanics(self) -> Dict[str, int]:\n",
    "        \"\"\"Identify prevalent mechanics in the format\"\"\"\n",
    "        mechanics = Counter()\n",
    "        \n",
    "        for _, card in self.card_db.iterrows():\n",
    "            # Check keywords array\n",
    "            if isinstance(card.keywords, list):\n",
    "                mechanics.update(card.keywords)\n",
    "            \n",
    "            # Check oracle text for mechanics\n",
    "            oracle_text = str(card.oracle_text) if pd.notna(card.oracle_text) else ''\n",
    "            \n",
    "            # Add regex patterns for common mechanics\n",
    "            mechanic_patterns = {\n",
    "                'adventure': r'adventure',\n",
    "                'convoke': r'convoke',\n",
    "                'prowess': r'prowess',\n",
    "                'food': r'food token|sacrifice a food',\n",
    "                'treasure': r'treasure token|sacrifice a treasure',\n",
    "                'investigate': r'investigate|sacrifice a clue',\n",
    "                'bargain': r'bargain',\n",
    "                'token': r'create.*token',\n",
    "                'sacrifice': r'sacrifice a',\n",
    "                'ward': r'ward',\n",
    "                'disturb': r'disturb',\n",
    "                'daybound': r'daybound',\n",
    "                'nightbound': r'nightbound',\n",
    "                'defender': r'defender',\n",
    "                'flash': r'flash',\n",
    "                'flying': r'flying',\n",
    "                'haste': r'haste',\n",
    "                'lifelink': r'lifelink',\n",
    "                'trample': r'trample',\n",
    "                'vigilance': r'vigilance'\n",
    "            }\n",
    "            \n",
    "            for mechanic, pattern in mechanic_patterns.items():\n",
    "                if re.search(pattern, oracle_text, re.IGNORECASE):\n",
    "                    mechanics[mechanic] += 1\n",
    "        \n",
    "        # Filter out mechanics that appear too rarely to be significant\n",
    "        min_threshold = len(self.card_db) * 0.01  # 1% of cards\n",
    "        return {k: v for k, v in mechanics.items() if v >= min_threshold}\n",
    "\n",
    "class LandAnalyzer:\n",
    "    \"\"\"Enhanced land analysis system\"\"\"\n",
    "    def __init__(self, card_db: pd.DataFrame):\n",
    "        self.card_db = card_db\n",
    "        self.land_cycles = self._identify_land_cycles()\n",
    "        \n",
    "    def _identify_land_cycles(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"Automatically identify land cycles based on text patterns\"\"\"\n",
    "        lands = self.card_db[self.card_db['is_land']].copy()\n",
    "        cycles = defaultdict(list)\n",
    "        \n",
    "        # First handle basic lands\n",
    "        for _, land in lands.iterrows():\n",
    "            if 'Basic' in land['type_line']:\n",
    "                cycles['basic_lands'].append(land['name'])\n",
    "        \n",
    "        # Remove basic lands for cycle analysis\n",
    "        nonbasic_lands = lands[~lands['type_line'].str.contains('Basic', na=False)]\n",
    "        \n",
    "        # Common land effects to identify\n",
    "        effect_patterns = {\n",
    "            'damage': (r'(deals|pay|lose) \\d+ (damage|life)', 'pain_lands'),\n",
    "            'life_gain': (r'gain \\d+ life', 'life_lands'),\n",
    "            'scry': (r'scry \\d+', 'scry_lands'),\n",
    "            'surveil': (r'surveil \\d+', 'surveil_lands'),\n",
    "            'fetch': (r'search .* library .* land', 'fetch_lands'),\n",
    "            'shock': (r'pay 2 life', 'shock_lands'),\n",
    "            'tap_condition_two_or_fewer': (r'tapped unless .* two or fewer', 'fast_lands'),\n",
    "            'tap_condition_two_or_more': (r'tapped unless .* two or more', 'slow_lands'),\n",
    "            'tap_condition_basic': (r'tapped unless .* control a (Plains|Island|Swamp|Mountain|Forest)', 'check_lands'),\n",
    "            'reveal_condition': (r'reveal a .* card', 'reveal_lands'),\n",
    "            'dual_faced': (r'//', 'pathway_lands'),\n",
    "            'triome': (r'Triome', 'triome_lands'),\n",
    "            'bicycle': (r'cycling.*\\{2\\}', 'bicycle_lands'),\n",
    "            'bounce': (r'return .* land .* hand', 'bounce_lands'),\n",
    "            'storage': (r'storage counter|charge counter', 'storage_lands'),\n",
    "            'man_land': (r'becomes? a.*creature.*until end of turn', 'man_lands')\n",
    "        }\n",
    "        \n",
    "        # Identify lands that don't match any specific cycle\n",
    "        for _, land in nonbasic_lands.iterrows():\n",
    "            oracle_text = str(land['oracle_text']) if pd.notna(land['oracle_text']) else ''\n",
    "            \n",
    "            # Try to match known effects\n",
    "            matched = False\n",
    "            for effect, (pattern, cycle_name) in effect_patterns.items():\n",
    "                if re.search(pattern, oracle_text, re.IGNORECASE):\n",
    "                    cycles[cycle_name].append(land['name'])\n",
    "                    matched = True\n",
    "                    break\n",
    "            \n",
    "            # Check for specific mana production patterns\n",
    "            produced_mana = land.produced_mana if isinstance(land.produced_mana, list) else []\n",
    "            if produced_mana:\n",
    "                if len(produced_mana) > 1:\n",
    "                    if not matched:  # Only categorize if not already matched\n",
    "                        cycles['dual_lands'].append(land['name'])\n",
    "                elif not matched:\n",
    "                    cycles['utility_lands'].append(land['name'])\n",
    "            elif not matched:\n",
    "                # Lands with unique effects\n",
    "                cycles['special_lands'].append(land['name'])\n",
    "        \n",
    "        # Post-process to identify cycles by name patterns\n",
    "        cycle_groups = self._group_lands_by_patterns(cycles)\n",
    "        \n",
    "        # Add back basic and special lands\n",
    "        cycle_groups['basic_lands'] = cycles['basic_lands']\n",
    "        cycle_groups['special_lands'] = cycles['special_lands']\n",
    "        \n",
    "        return dict(cycle_groups)\n",
    "    \n",
    "    def _group_lands_by_patterns(self, cycles: Dict[str, List[str]]) -> Dict[str, List[str]]:\n",
    "        \"\"\"Group lands by name patterns and return restructured cycles\"\"\"\n",
    "        cycle_groups = defaultdict(list)\n",
    "        \n",
    "        # Common naming patterns for land cycles\n",
    "        name_patterns = {\n",
    "            'fastland': ['seachrome', 'darkslick', 'copperline', 'razorverge', 'blackcleave'],\n",
    "            'slowland': ['deserted', 'deathcap', 'dreamroot', 'haunted', 'sundown'],\n",
    "            'checkland': ['glacial', 'drowned', 'woodland', 'clifftop', 'isolated'],\n",
    "            'shockland': ['hallowed', 'watery', 'overgrown', 'blood', 'stomping'],\n",
    "            'pathway': ['brightclimb', 'clearwater', 'darkbore', 'blightstep', 'needleverge']\n",
    "        }\n",
    "        \n",
    "        for cycle_name, lands in cycles.items():\n",
    "            if cycle_name not in ['basic_lands', 'special_lands']:\n",
    "                matched_lands = defaultdict(list)\n",
    "                \n",
    "                # Try to match lands to known naming patterns\n",
    "                for land in lands:\n",
    "                    land_lower = land.lower()\n",
    "                    matched = False\n",
    "                    \n",
    "                    for pattern_name, pattern_words in name_patterns.items():\n",
    "                        if any(word in land_lower for word in pattern_words):\n",
    "                            matched_lands[f\"{cycle_name}_{pattern_name}\"].append(land)\n",
    "                            matched = True\n",
    "                            break\n",
    "                    \n",
    "                    if not matched:\n",
    "                        matched_lands[cycle_name].append(land)\n",
    "                \n",
    "                # Add grouped lands to final cycles\n",
    "                for group_name, group_lands in matched_lands.items():\n",
    "                    if len(group_lands) >= 3:  # Minimum size for a cycle\n",
    "                        cycle_groups[group_name].extend(group_lands)\n",
    "                    else:\n",
    "                        cycle_groups[cycle_name].extend(group_lands)\n",
    "        \n",
    "        return cycle_groups\n",
    "\n",
    "class FormatAnalyzer:\n",
    "    \"\"\"Enhanced analyzer for format patterns and characteristics\"\"\"\n",
    "    def __init__(self, card_db: pd.DataFrame):\n",
    "        self.card_db = card_db\n",
    "        self.mechanics_analyzer = CardMechanics(card_db)\n",
    "        self.land_analyzer = LandAnalyzer(card_db)\n",
    "    \n",
    "    def analyze_format_characteristics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze overall format characteristics\"\"\"\n",
    "        try:\n",
    "            characteristics = {\n",
    "                'speed_indicators': self._analyze_format_speed(),\n",
    "                'mechanics': self.mechanics_analyzer.format_mechanics,\n",
    "                'mana_bases': self.land_analyzer.land_cycles,\n",
    "                'power_cards': self._identify_power_cards(),\n",
    "                'synergy_clusters': self._identify_synergy_clusters()\n",
    "            }\n",
    "            return characteristics\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error analyzing format characteristics: {str(e)}\")\n",
    "            return {\n",
    "                'speed_indicators': {},\n",
    "                'mechanics': {},\n",
    "                'mana_bases': {},\n",
    "                'power_cards': [],\n",
    "                'synergy_clusters': {}\n",
    "            }\n",
    "    \n",
    "    def _analyze_format_speed(self) -> Dict[str, float]:\n",
    "        \"\"\"Analyze format speed based on available cards\"\"\"\n",
    "        try:\n",
    "            nonland_cards = self.card_db[~self.card_db['is_land']]\n",
    "            if nonland_cards.empty:\n",
    "                return self._get_default_speed_indicators()\n",
    "            \n",
    "            interaction_cards = nonland_cards[\n",
    "                nonland_cards['oracle_text'].str.contains('counter|destroy|exile', \n",
    "                                                        na=False, case=False)\n",
    "            ]\n",
    "            \n",
    "            # Handle power conversion safely\n",
    "            creature_cards = nonland_cards[nonland_cards['is_creature']]\n",
    "            fast_threats = creature_cards[\n",
    "                (creature_cards['cmc'] <= 2) & \n",
    "                creature_cards['power'].apply(\n",
    "                    lambda x: str(x).isdigit() and int(str(x)) >= 2 if pd.notna(x) else False\n",
    "                )\n",
    "            ]\n",
    "            \n",
    "            return {\n",
    "                'avg_cmc': nonland_cards['cmc'].mean(),\n",
    "                'median_cmc': nonland_cards['cmc'].median(),\n",
    "                'one_drops': len(nonland_cards[nonland_cards['cmc'] == 1]),\n",
    "                'two_drops': len(nonland_cards[nonland_cards['cmc'] == 2]),\n",
    "                'interaction_cmc': interaction_cards['cmc'].mean() if not interaction_cards.empty else 0,\n",
    "                'creature_avg_cmc': creature_cards['cmc'].mean() if not creature_cards.empty else 0,\n",
    "                'early_interaction': len(interaction_cards[interaction_cards['cmc'] <= 2]),\n",
    "                'fast_threats': len(fast_threats)\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error analyzing format speed: {str(e)}\")\n",
    "            return self._get_default_speed_indicators()\n",
    "    \n",
    "    def _get_default_speed_indicators(self) -> Dict[str, float]:\n",
    "        \"\"\"Return default speed indicators\"\"\"\n",
    "        return {\n",
    "            'avg_cmc': 0.0,\n",
    "            'median_cmc': 0.0,\n",
    "            'one_drops': 0,\n",
    "            'two_drops': 0,\n",
    "            'interaction_cmc': 0.0,\n",
    "            'creature_avg_cmc': 0.0,\n",
    "            'early_interaction': 0,\n",
    "            'fast_threats': 0\n",
    "        }\n",
    "    \n",
    "    def _identify_power_cards(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Identify potentially powerful cards based on characteristics\"\"\"\n",
    "        power_cards = []\n",
    "        \n",
    "        for _, card in self.card_db.iterrows():\n",
    "            try:\n",
    "                power_score = self._calculate_power_score(card)\n",
    "                if power_score >= 2:\n",
    "                    power_cards.append({\n",
    "                        'name': card['name'],\n",
    "                        'score': power_score,\n",
    "                        'cmc': card['cmc'],\n",
    "                        'colors': card['colors'],\n",
    "                        'type': card['type_line'],\n",
    "                        'keywords': card['keywords'] if isinstance(card['keywords'], list) else []\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error calculating power score for {card['name']}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        return sorted(power_cards, key=lambda x: x['score'], reverse=True)[:20]\n",
    "    \n",
    "    def _calculate_power_score(self, card: pd.Series) -> float:\n",
    "        \"\"\"Calculate power score for a single card\"\"\"\n",
    "        power_score = 0\n",
    "        oracle_text = str(card['oracle_text']) if pd.notna(card['oracle_text']) else ''\n",
    "        \n",
    "        # Evaluate creature stats\n",
    "        if card['is_creature']:\n",
    "            power = str(card['power'])\n",
    "            toughness = str(card['toughness'])\n",
    "            if power.replace('.','',1).isdigit() and toughness.replace('.','',1).isdigit():\n",
    "                total_stats = float(power) + float(toughness)\n",
    "                if total_stats > 0 and card['cmc'] > 0:\n",
    "                    power_score += total_stats / card['cmc']\n",
    "        \n",
    "        # Evaluate mana efficiency\n",
    "        if card['cmc'] > 0:\n",
    "            # Efficient creatures\n",
    "            if card['is_creature']:\n",
    "                power = str(card['power'])\n",
    "                toughness = str(card['toughness'])\n",
    "                if power.replace('.','',1).isdigit() and toughness.replace('.','',1).isdigit():\n",
    "                    total_stats = float(power) + float(toughness)\n",
    "                    if total_stats > card['cmc'] * 2:\n",
    "                        power_score += 1\n",
    "            \n",
    "            # Efficient interaction\n",
    "            if any(text in oracle_text.lower() for text in ['counter target spell', 'destroy target']):\n",
    "                if card['cmc'] <= 2:\n",
    "                    power_score += 1.5\n",
    "                elif card['cmc'] <= 3:\n",
    "                    power_score += 1\n",
    "        \n",
    "        # Card advantage evaluation\n",
    "        card_advantage_words = ['draw', 'search your library', 'return target', 'exile']\n",
    "        power_score += sum(0.5 for word in card_advantage_words if word in oracle_text.lower())\n",
    "        \n",
    "        # Evaluate versatility\n",
    "        if card['layout'] == 'adventure' or '//' in str(card['full_name']):\n",
    "            power_score += 0.5\n",
    "        \n",
    "        # Evaluate keywords\n",
    "        valuable_keywords = ['flying', 'haste', 'ward', 'flash', 'deathtouch', 'trample', 'lifelink']\n",
    "        if isinstance(card['keywords'], list):\n",
    "            power_score += sum(0.3 for k in card['keywords'] if k in valuable_keywords)\n",
    "        \n",
    "        # Evaluate planeswalker potential\n",
    "        if 'Planeswalker' in str(card['type_line']):\n",
    "            power_score += 1\n",
    "        \n",
    "        # Evaluate board impact\n",
    "        impact_phrases = ['each creature', 'all creatures', 'each player', 'each opponent']\n",
    "        power_score += sum(0.5 for phrase in impact_phrases if phrase in oracle_text.lower())\n",
    "        \n",
    "        return power_score\n",
    "    \n",
    "    def _identify_synergy_clusters(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"Identify clusters of cards with potential synergies\"\"\"\n",
    "        try:\n",
    "            themes = defaultdict(list)\n",
    "            \n",
    "            # Define synergy patterns with required types\n",
    "            synergy_patterns = {\n",
    "                'artifact': (r'artifact|create \\w+ artifact|sacrifice an artifact', ['Artifact']),\n",
    "                'token': (r'create \\w+ token|whenever a creature token|creatures you control get', ['Creature']),\n",
    "                'graveyard': (r'from.*graveyard|cards in graveyards|exile.*from.*graveyard', None),\n",
    "                'spell_matters': (r'whenever you cast|prowess|magecraft', ['Instant', 'Sorcery']),\n",
    "                'sacrifice': (r'sacrifice a creature|whenever a creature you control dies', ['Creature']),\n",
    "                'counter': (r'counter target|whenever a spell is countered', ['Instant']),\n",
    "                'enchantment': (r'enchantment|aura|constellation', ['Enchantment'])\n",
    "            }\n",
    "            \n",
    "            for _, card in self.card_db.iterrows():\n",
    "                try:\n",
    "                    oracle_text = str(card['oracle_text']) if pd.notna(card['oracle_text']) else ''\n",
    "                    type_line = str(card['type_line'])\n",
    "                    \n",
    "                    # Check for tribe-specific synergies\n",
    "                    if 'Creature' in type_line:\n",
    "                        creature_types = re.findall(r'(?<=\\—\\s)([^—]+?)(?=\\s(?:\\$|$|\\}))', type_line)\n",
    "                        for creature_type in creature_types:\n",
    "                            if re.search(f\"{creature_type}s? you control\", oracle_text, re.IGNORECASE):\n",
    "                                themes[f'tribal_{creature_type.lower()}'].append(card['name'])\n",
    "                    \n",
    "                    # Check for mechanical synergies\n",
    "                    for synergy_name, (pattern, required_types) in synergy_patterns.items():\n",
    "                        if re.search(pattern, oracle_text, re.IGNORECASE):\n",
    "                            if required_types is None or any(t in type_line for t in required_types):\n",
    "                                themes[synergy_name].append(card['name'])\n",
    "                    \n",
    "                    # Check for keyword-based synergies\n",
    "                    if isinstance(card['keywords'], list):\n",
    "                        for keyword in card['keywords']:\n",
    "                            keyword_lower = keyword.lower()\n",
    "                            if re.search(f\"{keyword_lower}|{keyword_lower}s\", oracle_text, re.IGNORECASE):\n",
    "                                themes[f'{keyword_lower}_matters'].append(card['name'])\n",
    "                                \n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Error processing synergies for {card['name']}: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            # Filter out themes with too few or too many cards\n",
    "            min_cards = 3\n",
    "            max_cards = len(self.card_db) * 0.2  # 20% of total cards\n",
    "            return {theme: cards for theme, cards in themes.items() \n",
    "                   if min_cards <= len(cards) <= max_cards}\n",
    "                   \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error identifying synergy clusters: {str(e)}\")\n",
    "            return {}\n",
    "\n",
    "class DeckClassifier:\n",
    "    def __init__(self, card_db: pd.DataFrame):\n",
    "        self.card_db = card_db\n",
    "        self.archetype_characteristics = DeckArchetype.get_characteristics()\n",
    "\n",
    "    def _find_card_in_db(self, card_name: str) -> pd.Series:\n",
    "        \"\"\"Find a card in the database, handling split cards\"\"\"\n",
    "        # Try exact match first\n",
    "        exact_match = self.card_db[self.card_db['name'] == card_name]\n",
    "        if not exact_match.empty:\n",
    "            return exact_match.iloc[0]\n",
    "            \n",
    "        # Try case-insensitive match\n",
    "        card_name_lower = card_name.lower()\n",
    "        case_insensitive_match = self.card_db[self.card_db['name_lower'] == card_name_lower]\n",
    "        if not case_insensitive_match.empty:\n",
    "            return case_insensitive_match.iloc[0]\n",
    "            \n",
    "        # Try matching split card parts\n",
    "        if '/' in card_name:\n",
    "            parts = [part.strip().lower() for part in card_name.split('/')]\n",
    "            for part in parts:\n",
    "                match = self.card_db[self.card_db['name_lower'].str.contains(part, regex=False, na=False)]\n",
    "                if not match.empty:\n",
    "                    return match.iloc[0]\n",
    "        \n",
    "        raise ValueError(f\"Card not found: {card_name}\")\n",
    "        \n",
    "    def classify_deck(self, decklist: List[str]) -> Dict[str, Any]:\n",
    "        \"\"\"Classify deck with confidence scores for each archetype\"\"\"\n",
    "        try:\n",
    "            deck_stats = self._calculate_deck_statistics(decklist)\n",
    "            archetype_scores = self._calculate_archetype_scores(deck_stats)\n",
    "            \n",
    "            if not archetype_scores:\n",
    "                return {\n",
    "                    'primary_archetype': DeckArchetype.UNKNOWN.value,\n",
    "                    'subtype': None,\n",
    "                    'confidence_scores': {},\n",
    "                    'statistics': deck_stats\n",
    "                }\n",
    "            \n",
    "            # Get primary and secondary archetypes\n",
    "            sorted_scores = sorted(archetype_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "            primary_archetype = sorted_scores[0][0]\n",
    "            \n",
    "            # Check if deck is a hybrid\n",
    "            if len(sorted_scores) > 1 and sorted_scores[1][1] > sorted_scores[0][1] * 0.8:\n",
    "                classification = DeckArchetype.HYBRID.value\n",
    "                subtype = f\"{sorted_scores[0][0].value}-{sorted_scores[1][0].value}\"\n",
    "            else:\n",
    "                classification = primary_archetype.value\n",
    "                subtype = None\n",
    "            \n",
    "            return {\n",
    "                'primary_archetype': classification,\n",
    "                'subtype': subtype,\n",
    "                'confidence_scores': archetype_scores,\n",
    "                'statistics': deck_stats\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error classifying deck: {str(e)}\")\n",
    "            return {\n",
    "                'primary_archetype': DeckArchetype.UNKNOWN.value,\n",
    "                'subtype': None,\n",
    "                'confidence_scores': {},\n",
    "                'statistics': self._get_default_stats()\n",
    "            }\n",
    "    \n",
    "    def _calculate_deck_statistics(self, decklist: List[str]) -> Dict[str, float]:\n",
    "        \"\"\"Calculate comprehensive deck statistics\"\"\"\n",
    "        try:\n",
    "            # Find all cards in database\n",
    "            deck_cards = []\n",
    "            for card_name in decklist:\n",
    "                try:\n",
    "                    card = self._find_card_in_db(card_name)\n",
    "                    deck_cards.append(card)\n",
    "                except ValueError as e:\n",
    "                    logger.warning(str(e))\n",
    "            \n",
    "            if not deck_cards:\n",
    "                return self._get_default_stats()\n",
    "            \n",
    "            # Separate nonland cards\n",
    "            nonland_cards = [card for card in deck_cards if not card['is_land']]\n",
    "            if not nonland_cards:\n",
    "                return self._get_default_stats()\n",
    "            \n",
    "            # Calculate curve\n",
    "            curve = self._calculate_curve(deck_cards)\n",
    "            curve_peak = max(curve.items(), key=lambda x: x[1])[0] if curve else 0\n",
    "            \n",
    "            # Calculate statistics\n",
    "            stats = {\n",
    "                'creature_ratio': sum(1 for card in nonland_cards if card['is_creature']) / len(nonland_cards),\n",
    "                'avg_cmc': np.mean([card['cmc'] for card in nonland_cards]),\n",
    "                'curve_peak': curve_peak,\n",
    "                'removal_ratio': self._calculate_removal_ratio(nonland_cards),\n",
    "                'interaction_ratio': self._calculate_interaction_ratio(nonland_cards),\n",
    "                'card_advantage_ratio': self._calculate_card_advantage_ratio(nonland_cards),\n",
    "                'early_game_ratio': self._calculate_early_game_ratio(curve),\n",
    "                'threat_density': self._calculate_threat_density(nonland_cards)\n",
    "            }\n",
    "            \n",
    "            return stats\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error calculating deck statistics: {str(e)}\")\n",
    "            return self._get_default_stats()\n",
    "\n",
    "    def _get_default_stats(self) -> Dict[str, float]:\n",
    "        \"\"\"Return default statistics when calculation fails\"\"\"\n",
    "        return {\n",
    "            'creature_ratio': 0.0,\n",
    "            'avg_cmc': 0.0,\n",
    "            'curve_peak': 0,\n",
    "            'removal_ratio': 0.0,\n",
    "            'interaction_ratio': 0.0,\n",
    "            'card_advantage_ratio': 0.0,\n",
    "            'early_game_ratio': 0.0,\n",
    "            'threat_density': 0.0\n",
    "        }\n",
    "    \n",
    "    def _calculate_curve(self, deck_cards: List[pd.Series]) -> Dict[int, int]:\n",
    "        \"\"\"Calculate mana curve of the deck\"\"\"\n",
    "        curve = defaultdict(int)\n",
    "        for card in deck_cards:\n",
    "            if not card['is_land']:\n",
    "                cmc = int(card['cmc'])\n",
    "                curve[cmc] += 1\n",
    "        return dict(curve)\n",
    "    \n",
    "    def _calculate_removal_ratio(self, nonland_cards: List[pd.Series]) -> float:\n",
    "        \"\"\"Calculate ratio of removal spells\"\"\"\n",
    "        removal_count = 0\n",
    "        removal_patterns = [\n",
    "            r'destroy target', r'exile target', r'deals? \\d+ damage to target',\n",
    "            r'target creature gets -\\d+/-\\d+', r'return target.*to.*hand'\n",
    "        ]\n",
    "        \n",
    "        for card in nonland_cards:\n",
    "            oracle_text = str(card['oracle_text']).lower() if pd.notna(card['oracle_text']) else ''\n",
    "            if any(re.search(pattern, oracle_text) for pattern in removal_patterns):\n",
    "                removal_count += 1\n",
    "                \n",
    "        return removal_count / len(nonland_cards) if nonland_cards else 0\n",
    "    \n",
    "    def _calculate_interaction_ratio(self, nonland_cards: List[pd.Series]) -> float:\n",
    "        \"\"\"Calculate ratio of interactive spells\"\"\"\n",
    "        interaction_count = 0\n",
    "        interaction_patterns = [\n",
    "            r'counter target', r'can\\'t attack', r'can\\'t block', r'tap target',\n",
    "            r'target.*doesn\\'t untap', r'protection from', r'hexproof', r'ward'\n",
    "        ]\n",
    "        \n",
    "        for card in nonland_cards:\n",
    "            oracle_text = str(card['oracle_text']).lower() if pd.notna(card['oracle_text']) else ''\n",
    "            if any(re.search(pattern, oracle_text) for pattern in interaction_patterns):\n",
    "                interaction_count += 1\n",
    "                \n",
    "        return interaction_count / len(nonland_cards) if nonland_cards else 0\n",
    "    \n",
    "    def _calculate_card_advantage_ratio(self, nonland_cards: List[pd.Series]) -> float:\n",
    "        \"\"\"Calculate ratio of card advantage spells\"\"\"\n",
    "        advantage_count = 0\n",
    "        advantage_patterns = [\n",
    "            r'draw \\w+ cards?', r'search your library', r'investigate',\n",
    "            r'surveil \\d+', r'scry \\d+', r'return.*from your graveyard'\n",
    "        ]\n",
    "        \n",
    "        for card in nonland_cards:\n",
    "            oracle_text = str(card['oracle_text']).lower() if pd.notna(card['oracle_text']) else ''\n",
    "            if any(re.search(pattern, oracle_text) for pattern in advantage_patterns):\n",
    "                advantage_count += 1\n",
    "                \n",
    "        return advantage_count / len(nonland_cards) if nonland_cards else 0\n",
    "    \n",
    "    def _calculate_early_game_ratio(self, curve: Dict[int, int]) -> float:\n",
    "        \"\"\"Calculate ratio of early game plays (CMC 1-2)\"\"\"\n",
    "        early_game_count = sum(count for cmc, count in curve.items() if cmc <= 2)\n",
    "        total_cards = sum(curve.values())\n",
    "        return early_game_count / total_cards if total_cards > 0 else 0\n",
    "    \n",
    "    def _calculate_threat_density(self, nonland_cards: List[pd.Series]) -> float:\n",
    "        \"\"\"Calculate ratio of threats in the deck\"\"\"\n",
    "        threat_count = 0\n",
    "        \n",
    "        for card in nonland_cards:\n",
    "            # Consider creatures with power 3 or greater as threats\n",
    "            if card['is_creature']:\n",
    "                power = str(card['power'])\n",
    "                if power.isdigit() and int(power) >= 3:\n",
    "                    threat_count += 1\n",
    "            \n",
    "            # Consider planeswalkers as threats\n",
    "            if 'Planeswalker' in str(card['type_line']):\n",
    "                threat_count += 1\n",
    "                \n",
    "        return threat_count / len(nonland_cards) if nonland_cards else 0\n",
    "    \n",
    "    def _calculate_archetype_scores(self, deck_stats: Dict[str, float]) -> Dict[DeckArchetype, float]:\n",
    "        \"\"\"Calculate confidence scores for each archetype\"\"\"\n",
    "        scores = {}\n",
    "        \n",
    "        for archetype in DeckArchetype:\n",
    "            if archetype in [DeckArchetype.HYBRID, DeckArchetype.UNKNOWN]:\n",
    "                continue\n",
    "                \n",
    "            characteristics = self.archetype_characteristics.get(archetype)\n",
    "            if not characteristics:\n",
    "                continue\n",
    "                \n",
    "            score = 0\n",
    "            total_checks = 0\n",
    "            \n",
    "            # Check all available statistics against archetype characteristics\n",
    "            if all(key in deck_stats for key in ['creature_ratio', 'removal_ratio', 'curve_peak',\n",
    "                                                'interaction_ratio', 'card_advantage_ratio', 'avg_cmc']):\n",
    "                # Check creature ratio\n",
    "                total_checks += 1\n",
    "                if characteristics.creature_ratio[0] <= deck_stats['creature_ratio'] <= characteristics.creature_ratio[1]:\n",
    "                    score += 1\n",
    "                \n",
    "                # Check removal ratio\n",
    "                total_checks += 1\n",
    "                if characteristics.removal_ratio[0] <= deck_stats['removal_ratio'] <= characteristics.removal_ratio[1]:\n",
    "                    score += 1\n",
    "                \n",
    "                # Check curve peak\n",
    "                total_checks += 1\n",
    "                if characteristics.curve_peak[0] <= deck_stats['curve_peak'] <= characteristics.curve_peak[1]:\n",
    "                    score += 1\n",
    "                \n",
    "                # Check interaction ratio\n",
    "                total_checks += 1\n",
    "                if characteristics.interaction_ratio[0] <= deck_stats['interaction_ratio'] <= characteristics.interaction_ratio[1]:\n",
    "                    score += 1\n",
    "                \n",
    "                # Check card advantage ratio\n",
    "                total_checks += 1\n",
    "                if characteristics.card_advantage_ratio[0] <= deck_stats['card_advantage_ratio'] <= characteristics.card_advantage_ratio[1]:\n",
    "                    score += 1\n",
    "                \n",
    "                # Check average CMC\n",
    "                total_checks += 1\n",
    "                if characteristics.avg_cmc[0] <= deck_stats['avg_cmc'] <= characteristics.avg_cmc[1]:\n",
    "                    score += 1\n",
    "            \n",
    "            # Calculate final score as percentage of matched characteristics\n",
    "            scores[archetype] = score / total_checks if total_checks > 0 else 0\n",
    "        \n",
    "        return scores\n",
    "\n",
    "class FormatMetaAnalyzer:\n",
    "    \"\"\"\n",
    "    Integrates all components for comprehensive format analysis\n",
    "    \"\"\"\n",
    "    def __init__(self, card_db: pd.DataFrame):\n",
    "        self.card_db = card_db\n",
    "        self.format_analyzer = FormatAnalyzer(card_db)\n",
    "        self.deck_classifier = DeckClassifier(card_db)\n",
    "        self.format_characteristics = None\n",
    "    \n",
    "    def analyze_meta(self, decklists: Dict[str, List[str]]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Perform comprehensive meta analysis\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Analyze format characteristics first\n",
    "            self.format_characteristics = self.format_analyzer.analyze_format_characteristics()\n",
    "            \n",
    "            # Analyze each deck\n",
    "            deck_analyses = {}\n",
    "            archetype_distribution = Counter()\n",
    "            card_frequencies = Counter()\n",
    "            \n",
    "            for deck_name, decklist in decklists.items():\n",
    "                try:\n",
    "                    deck_analysis = self._analyze_deck(deck_name, decklist)\n",
    "                    deck_analyses[deck_name] = deck_analysis\n",
    "                    archetype_distribution[deck_analysis['archetype']['primary_archetype']] += 1\n",
    "                    # Update frequencies only for verified cards\n",
    "                    card_frequencies.update(deck_analysis['verified_cards'])\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error analyzing deck {deck_name}: {str(e)}\")\n",
    "            \n",
    "            return {\n",
    "                'format_characteristics': self.format_characteristics,\n",
    "                'deck_analyses': deck_analyses,\n",
    "                'meta_statistics': self._calculate_meta_statistics(deck_analyses),\n",
    "                'archetype_distribution': dict(archetype_distribution),\n",
    "                'card_frequencies': dict(card_frequencies)\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in meta analysis: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _analyze_deck(self, deck_name: str, decklist: List[str]) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze individual deck\"\"\"\n",
    "        try:\n",
    "            # Verify all cards exist in database and handle split cards\n",
    "            missing_cards = []\n",
    "            verified_cards = []\n",
    "            \n",
    "            for card in decklist:\n",
    "                try:\n",
    "                    card_data = self.deck_classifier._find_card_in_db(card)\n",
    "                    verified_cards.append(card_data['name'])\n",
    "                except ValueError:\n",
    "                    missing_cards.append(card)\n",
    "            \n",
    "            if missing_cards:\n",
    "                logger.warning(f\"Missing cards in {deck_name}: {missing_cards}\")\n",
    "            \n",
    "            # Get deck classification using only verified cards\n",
    "            classification = self.deck_classifier.classify_deck(verified_cards)\n",
    "            \n",
    "            # Analyze deck's alignment with format characteristics\n",
    "            format_alignment = self._analyze_format_alignment(verified_cards)\n",
    "            \n",
    "            return {\n",
    "                'name': deck_name,\n",
    "                'archetype': classification,\n",
    "                'format_alignment': format_alignment,\n",
    "                'card_count': len(verified_cards),\n",
    "                'missing_cards': missing_cards,\n",
    "                'verified_cards': verified_cards\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error analyzing deck {deck_name}: {str(e)}\")\n",
    "            return {\n",
    "                'name': deck_name,\n",
    "                'archetype': {'primary_archetype': DeckArchetype.UNKNOWN.value, \n",
    "                            'statistics': self.deck_classifier._get_default_stats()},\n",
    "                'format_alignment': {'mechanics_alignment': 0.0, 'power_card_alignment': 0.0},\n",
    "                'card_count': len(decklist),\n",
    "                'missing_cards': decklist,\n",
    "                'verified_cards': []\n",
    "            }\n",
    "    \n",
    "    def _calculate_meta_statistics(self, deck_analyses: Dict[str, Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"Calculate comprehensive meta statistics\"\"\"\n",
    "        if not deck_analyses:\n",
    "            return {}\n",
    "        \n",
    "        # Calculate various statistics\n",
    "        stats = {\n",
    "            'average_statistics': self._calculate_average_stats(deck_analyses),\n",
    "            'format_speed': self._evaluate_format_speed(deck_analyses),\n",
    "            'color_distribution': self._analyze_color_distribution(deck_analyses),\n",
    "            'archetype_matchups': self._analyze_archetype_matchups(deck_analyses),\n",
    "            'meta_diversity': self._calculate_meta_diversity(deck_analyses)\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def _calculate_average_stats(self, deck_analyses: Dict[str, Dict]) -> Dict[str, float]:\n",
    "        \"\"\"Calculate average statistics across all decks\"\"\"\n",
    "        avg_stats = defaultdict(float)\n",
    "        count = len(deck_analyses)\n",
    "        \n",
    "        for analysis in deck_analyses.values():\n",
    "            if 'statistics' in analysis['archetype']:\n",
    "                stats = analysis['archetype']['statistics']\n",
    "                for key, value in stats.items():\n",
    "                    avg_stats[key] += value\n",
    "        \n",
    "        return {key: value/count for key, value in avg_stats.items()} if count > 0 else {}\n",
    "    \n",
    "    def _evaluate_format_speed(self, deck_analyses: Dict[str, Dict]) -> str:\n",
    "        \"\"\"Evaluate overall format speed\"\"\"\n",
    "        valid_analyses = [\n",
    "            analysis for analysis in deck_analyses.values()\n",
    "            if 'statistics' in analysis['archetype'] \n",
    "            and 'avg_cmc' in analysis['archetype']['statistics']\n",
    "        ]\n",
    "        \n",
    "        if not valid_analyses:\n",
    "            return \"unknown\"\n",
    "            \n",
    "        avg_cmc = np.mean([\n",
    "            analysis['archetype']['statistics']['avg_cmc'] \n",
    "            for analysis in valid_analyses\n",
    "        ])\n",
    "        \n",
    "        aggro_count = sum(\n",
    "            1 for analysis in deck_analyses.values() \n",
    "            if analysis['archetype']['primary_archetype'] == 'aggro'\n",
    "        )\n",
    "        \n",
    "        aggro_ratio = aggro_count / len(deck_analyses)\n",
    "        \n",
    "        if avg_cmc < 2.5 and aggro_ratio > 0.3:\n",
    "            return \"fast\"\n",
    "        elif avg_cmc > 3.5:\n",
    "            return \"slow\"\n",
    "        else:\n",
    "            return \"medium\"\n",
    "    \n",
    "    def _analyze_color_distribution(self, deck_analyses: Dict[str, Dict]) -> Dict[str, int]:\n",
    "        \"\"\"Analyze color distribution in the meta\"\"\"\n",
    "        color_counts = Counter()\n",
    "        \n",
    "        for analysis in deck_analyses.values():\n",
    "            deck_colors = set()\n",
    "            # Use verified_cards instead of deck name\n",
    "            for card_name in analysis['verified_cards']:\n",
    "                card_data = self.card_db[self.card_db['name'] == card_name]\n",
    "                if not card_data.empty:\n",
    "                    colors = card_data.iloc[0]['colors']\n",
    "                    if isinstance(colors, list):\n",
    "                        deck_colors.update(colors)\n",
    "            \n",
    "            if deck_colors:  # Only count if we found colors\n",
    "                color_counts[tuple(sorted(deck_colors))] += 1\n",
    "            \n",
    "        return dict(color_counts)\n",
    "    \n",
    "    def _analyze_archetype_matchups(self, deck_analyses: Dict[str, Dict]) -> Dict[str, Dict[str, float]]:\n",
    "        \"\"\"Analyze theoretical archetype matchups based on characteristics\"\"\"\n",
    "        archetypes = set(analysis['archetype']['primary_archetype'] \n",
    "                        for analysis in deck_analyses.values())\n",
    "        \n",
    "        matchups = {}\n",
    "        for arch1 in archetypes:\n",
    "            matchups[arch1] = {}\n",
    "            for arch2 in archetypes:\n",
    "                if arch1 != arch2:\n",
    "                    matchups[arch1][arch2] = self._calculate_matchup_score(arch1, arch2, deck_analyses)\n",
    "                else:\n",
    "                    matchups[arch1][arch2] = 0.5  # Mirror match\n",
    "                \n",
    "        return matchups\n",
    "    \n",
    "    def _calculate_matchup_score(self, arch1: str, arch2: str, \n",
    "                               deck_analyses: Dict[str, Dict]) -> float:\n",
    "        \"\"\"Calculate theoretical matchup score between two archetypes\"\"\"\n",
    "        arch1_decks = [a for a in deck_analyses.values() \n",
    "                      if a['archetype']['primary_archetype'] == arch1\n",
    "                      and 'statistics' in a['archetype']]\n",
    "        arch2_decks = [a for a in deck_analyses.values() \n",
    "                      if a['archetype']['primary_archetype'] == arch2\n",
    "                      and 'statistics' in a['archetype']]\n",
    "        \n",
    "        if not arch1_decks or not arch2_decks:\n",
    "            return 0.5\n",
    "        \n",
    "        # Compare key characteristics that influence matchups\n",
    "        score = 0.5  # Start at neutral\n",
    "        \n",
    "        # Average stats for each archetype\n",
    "        arch1_stats = self._average_archetype_stats(arch1_decks)\n",
    "        arch2_stats = self._average_archetype_stats(arch2_decks)\n",
    "        \n",
    "        # Only adjust score if we have the necessary statistics\n",
    "        if all(key in arch1_stats and key in arch2_stats \n",
    "               for key in ['avg_cmc', 'interaction_ratio', 'card_advantage_ratio']):\n",
    "            if arch1_stats['avg_cmc'] < arch2_stats['avg_cmc']:\n",
    "                score += 0.1\n",
    "            if arch1_stats['interaction_ratio'] > arch2_stats['interaction_ratio']:\n",
    "                score += 0.1\n",
    "            if arch1_stats['card_advantage_ratio'] > arch2_stats['card_advantage_ratio']:\n",
    "                score += 0.1\n",
    "            \n",
    "        return min(max(score, 0.3), 0.7)  # Keep within reasonable bounds\n",
    "    \n",
    "    def _average_archetype_stats(self, decks: List[Dict]) -> Dict[str, float]:\n",
    "        \"\"\"Calculate average statistics for an archetype\"\"\"\n",
    "        avg_stats = defaultdict(float)\n",
    "        count = 0\n",
    "        \n",
    "        for deck in decks:\n",
    "            if 'statistics' in deck['archetype']:\n",
    "                stats = deck['archetype']['statistics']\n",
    "                for key, value in stats.items():\n",
    "                    avg_stats[key] += value\n",
    "                count += 1\n",
    "        \n",
    "        return {key: value/count for key, value in avg_stats.items()} if count > 0 else {}\n",
    "    \n",
    "    def _calculate_meta_diversity(self, deck_analyses: Dict[str, Dict]) -> Dict[str, float]:\n",
    "        \"\"\"Calculate meta diversity metrics\"\"\"\n",
    "        total_decks = len(deck_analyses)\n",
    "        if total_decks == 0:\n",
    "            return {\n",
    "                'shannon_diversity': 0.0,\n",
    "                'effective_archetypes': 0.0,\n",
    "                'archetype_count': 0,\n",
    "                'most_popular_archetype_share': 0.0\n",
    "            }\n",
    "            \n",
    "        archetype_counts = Counter(\n",
    "            analysis['archetype']['primary_archetype'] \n",
    "            for analysis in deck_analyses.values()\n",
    "        )\n",
    "        \n",
    "        # Calculate Shannon diversity index\n",
    "        proportions = [count/total_decks for count in archetype_counts.values()]\n",
    "        shannon_diversity = -sum(p * np.log(p) for p in proportions)\n",
    "        \n",
    "        # Calculate effective number of archetypes\n",
    "        effective_archetypes = np.exp(shannon_diversity)\n",
    "        \n",
    "        return {\n",
    "            'shannon_diversity': shannon_diversity,\n",
    "            'effective_archetypes': effective_archetypes,\n",
    "            'archetype_count': len(archetype_counts),\n",
    "            'most_popular_archetype_share': max(proportions)\n",
    "        }\n",
    "    \n",
    "    def _analyze_format_alignment(self, decklist: List[str]) -> Dict[str, float]:\n",
    "        \"\"\"Analyze how well a deck aligns with format characteristics\"\"\"\n",
    "        alignment_scores = {}\n",
    "        \n",
    "        # Check mechanics alignment\n",
    "        deck_mechanics = self._identify_deck_mechanics(decklist)\n",
    "        mechanics_overlap = set(deck_mechanics) & set(self.format_characteristics['mechanics'].keys())\n",
    "        alignment_scores['mechanics_alignment'] = len(mechanics_overlap) / len(deck_mechanics) if deck_mechanics else 0\n",
    "        \n",
    "        # Check power card alignment\n",
    "        power_cards = set(card['name'] for card in self.format_characteristics['power_cards'])\n",
    "        deck_power_cards = set(decklist) & power_cards\n",
    "        alignment_scores['power_card_alignment'] = len(deck_power_cards) / len(decklist) if decklist else 0\n",
    "        \n",
    "        return alignment_scores\n",
    "    \n",
    "    def _identify_deck_mechanics(self, decklist: List[str]) -> Set[str]:\n",
    "        \"\"\"Identify mechanics present in a deck\"\"\"\n",
    "        mechanics = set()\n",
    "        for card in decklist:\n",
    "            card_data = self.card_db[self.card_db['name'] == card]\n",
    "            if not card_data.empty:\n",
    "                oracle_text = str(card_data.iloc[0]['oracle_text'])\n",
    "                for mechanic in self.format_characteristics['mechanics']:\n",
    "                    if mechanic.lower() in oracle_text.lower():\n",
    "                        mechanics.add(mechanic)\n",
    "        return mechanics\n",
    "\n",
    "def analyze_standard_format(cards_df: pd.DataFrame, decklists: Dict[str, List[str]]) -> None:\n",
    "    \"\"\"Main function to analyze Standard format\"\"\"\n",
    "    try:\n",
    "        meta_analyzer = FormatMetaAnalyzer(cards_df)\n",
    "        results = meta_analyzer.analyze_meta(decklists)\n",
    "        \n",
    "        # Print analysis results\n",
    "        print(\"\\n=== Standard Format Analysis ===\\n\")\n",
    "        \n",
    "        # Format speed and characteristics\n",
    "        print(\"Format Characteristics:\")\n",
    "        print(f\"Speed: {results['meta_statistics']['format_speed']}\")\n",
    "        print(f\"Effective number of archetypes: {results['meta_statistics']['meta_diversity']['effective_archetypes']:.2f}\")\n",
    "        \n",
    "        # Most common mechanics\n",
    "        print(\"\\nMost Common Mechanics:\")\n",
    "        for mechanic, count in sorted(results['format_characteristics']['mechanics'].items(),\n",
    "                                    key=lambda x: x[1], reverse=True)[:5]:\n",
    "            print(f\"- {mechanic}: {count} cards\")\n",
    "        \n",
    "        # Archetype distribution\n",
    "        print(\"\\nArchetype Distribution:\")\n",
    "        total_decks = sum(results['archetype_distribution'].values())\n",
    "        for archetype, count in sorted(results['archetype_distribution'].items(),\n",
    "                                     key=lambda x: x[1], reverse=True):\n",
    "            percentage = (count / total_decks) * 100\n",
    "            print(f\"{archetype}: {percentage:.1f}% ({count} decks)\")\n",
    "        \n",
    "        # Most played cards\n",
    "        print(\"\\nMost Played Cards (excluding lands):\")\n",
    "        for card, count in sorted(results['card_frequencies'].items(),\n",
    "                                key=lambda x: x[1], reverse=True)[:10]:\n",
    "            if not cards_df[cards_df['name'] == card]['is_land'].iloc[0]:\n",
    "                print(f\"{card}: {count} copies\")\n",
    "        \n",
    "        # Individual deck analysis\n",
    "        print(\"\\nDeck Analysis:\")\n",
    "        for deck_name, analysis in results['deck_analyses'].items():\n",
    "            print(f\"\\n{deck_name}:\")\n",
    "            print(f\"Archetype: {analysis['archetype']['primary_archetype']}\")\n",
    "            if analysis['archetype']['subtype']:\n",
    "                print(f\"Subtype: {analysis['archetype']['subtype']}\")\n",
    "            print(f\"Format Alignment: {analysis['format_alignment']['mechanics_alignment']:.2f}\")\n",
    "            if analysis['missing_cards']:\n",
    "                print(f\"Warning: {len(analysis['missing_cards'])} cards not found in database\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in format analysis: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess card database\n",
    "    cards_df = load_and_preprocess_data('data/standard_cards.csv')\n",
    "    \n",
    "    # Load decklists\n",
    "    decklists = load_decklists('current_standard_decks')\n",
    "    print(f\"Loaded {len(decklists)} decklists\")\n",
    "    \n",
    "    # Run analysis\n",
    "    analyze_standard_format(cards_df, decklists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0861d3a2-09ff-494b-90bd-ed742ee3ad42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
